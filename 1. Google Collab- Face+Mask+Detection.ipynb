{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell Number 1 Explanation:\n",
    "#### apt-get install is a linux command that installs library for your linux system.\n",
    "\n",
    "#### -q is a flag for apt-get install. It means Quiet. It produces output suitable for logging, omitting progress indicators. More q’s will produce more quiet up to a maximum of two. That’s why it’s written -qq.\n",
    "\n",
    "#### Sometimes while installing libraries, they may ask for your permission or something else for which you have to give option yes or y. -y is used for that. \n",
    "\n",
    "#### software-properties-common => this package contains the common files for software-properties. It manages the repositories that you install the software from (common). This software provides an abstraction of the used apt repositories.\n",
    "\n",
    "#### module-init-tools is for transitional dummy package. (Often packages in Ubuntu are replaced in newer releases by other packages, or they change name, or are merged into a single package or divided into multiple ones. To ease upgrading, these packages become “dummy” or “transitional” packages, which are practically empty files that depend on the newer packages)\n",
    "\n",
    "#### add-apt-repository => This commands add the repository to your system.\n",
    "\n",
    "#### ppa:alessandro-strada/ppa developed by Alessandro Strada => It mounts Google Drive on Ubuntu (via FUSE). FUSE is Filesystem in Userspace which is a simple interface for userspace programs to export a virtual filesystem to the Linux kernel. FUSE also aims to provide a secure method for non privileged users to create and mount their own filesystem implementations.\n",
    "\n",
    "#### /dev/null is a special file system object that throws away everything written into it. Redirecting a stream into it means hiding an output. \n",
    "\n",
    "#### The 2>&1 part means “redirect both the output and the error streams”. Even if your program writes to stderr , that output will not be shown.\n",
    "\n",
    "#### apt-get update -qq 2>&1 > /dev/null - Updates your system.\n",
    "\n",
    "#### apt-get -y install -qq google-drive-ocamlfuse fuse - It installs the google-drive-ocamlfuse library. google-drive-ocamlfuse is a FUSE filesystem backed by Google Drive, written in OCaml. It lets you mount your Google Drive on Linux.\n",
    "\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "#### After these, you will be needing some codes for auth. The above piece of code verifies your account to read files which you have access to. Make sure you have permission to read the file!\n",
    "\n",
    "#### creds = GoogleCredentials.get_application_default() - This returns the Application Default Credentials which are used to identify and authorize the whole application. The following are searched (in order) to find the Application Default Credentials:\n",
    "\n",
    "google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL =>\n",
    "#### This is a pipeline command that gets the verified URL after authentication is successfully done and also the the drive is mounted.\n",
    "\n",
    "#### vcode = getpass.getpass() => Gets a pass from getpass library.\n",
    "\n",
    "echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} =>\n",
    "#### It echos or shows the code returned after you clicked the URL returned by the grep URL command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configuration related preprocessing step before mounting the drive\n",
    "\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools \n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell Number 2 Explanation:\n",
    "#### Mounting the google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Mount the google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell Number 3 Explanation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"## Data Pre-processing\"\"\"\n",
    "\n",
    "# Import Necessary Libraries\n",
    "import os # The OS module in Python provides functions for interacting with the operating system. OS comes under Python's standard utility modules\n",
    "# Set Directory path for Dataset\n",
    "os.chdir(\"/content/drive/My Drive/Face\") # changing directory\n",
    "Dataset='Dataset'\n",
    "Data_Dir=os.listdir(Dataset) #listdir() returns a list containing the names of the entries in the directory given by path. The list is in arbitrary order. It does not include the special entries '.' and '..' even if they are present in the directory.\n",
    "print(Data_Dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell Number 4 Explanation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2 #OpenCV (Open Source Computer Vision Library) is a library of programming functions mainly aimed at real-time computer vision.\n",
    "import numpy as np #Numpy adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.\n",
    "#Using the method to_categorical(), a numpy array (or) a vector which has integers that represent different categories, can be converted into a numpy array (or) a matrix which has binary values and has columns equal to the number of categories in the data.\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "#Label Binarizer is an SciKit Learn class that accepts Categorical data as input and returns an Numpy array. it encodes the data into dummy variables indicating the presence of a particular label or not. Encoding make column data using Label Binarizer.\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split #Used to split testing and training data\n",
    "\n",
    "#Dimension of single image i.e. 112x112 pixels\n",
    "img_rows, img_cols = 112, 112\n",
    "\n",
    "#Defining 2 empty lists\n",
    "images = [] #will contain images after grey scaling and b sizing\n",
    "labels = [] #will contain labels corresponding to the classes of image i.e. with and without mask\n",
    "\n",
    "#Now we are using nested for loop \n",
    "#1st for loop =>  we will get directory path as /content/drive/My Drive/Face/Dataset/With mask\n",
    "#2nd for loop => to get the list of all image files in the specific directory\n",
    "for category in Data_Dir:\n",
    "    folder_path = os.path.join(Dataset, category)\n",
    "    for img in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img) # now join folder_path with each image using seperator /\n",
    "        img=cv2.imread(img_path) # then reading that image with imread function\n",
    "\n",
    "        try:\n",
    "            #Coverting the image into gray scale\n",
    "            grayscale_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            #resizing the gray scaled image into size 56x56 in order to keep size of the images consistent           \n",
    "            resized_img=cv2.resize(grayscale_img,(img_rows, img_cols))\n",
    "            images.append(resized_img)\n",
    "            labels.append(category)\n",
    "        # Exception Handling in case any error occurs\n",
    "        except Exception as e:\n",
    "            print('Exception:',e)\n",
    "        \n",
    "images=np.array(images)/255.0 # Normalizing an image\n",
    "images=np.reshape(images,(images.shape[0],img_rows, img_cols,1)) # resizing without changing data of image array\n",
    "\n",
    "# Perform one hot encoding on the labels since the label are in textual form so that it can be understood by our deep learning model\n",
    "lb = LabelBinarizer() # using LabelBinarizer() from sklearn.pre-processing package and creating its object named lb\n",
    "labels = lb.fit_transform(labels) # fit_transform to apply LabelBinarizer on each label\n",
    "labels = to_categorical(labels)# to_categorical to convert labels to hot encoded form\n",
    "labels = np.array(labels) #and converting it into array which is understandable by deep learning model using numpy array function\n",
    "\n",
    "(train_X, test_X, train_y, test_y) = train_test_split(images, labels, test_size=0.25, \n",
    "                                                      random_state=0)# splitting data into testing and training (here test data size 25%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A convolutional neural network consists of an input layer, hidden layers and an output layer. In any feed-forward neural network, any middle layers are called hidden because their inputs and outputs are masked by the activation function and final convolution. In a convolutional neural network, the hidden layers include layers that perform convolutions. Typically this includes a layer that does multiplication or other dot product, and its activation function is commonly ReLU. This is followed by other convolution layers such as pooling layers, fully connected layers and normalization layers.\n",
    "\n",
    "### A Convolutional Neural Network (CNN) architecture has three main parts:\n",
    "\n",
    "#### A convolutional layer that extracts features from a source image. Convolution helps with blurring, sharpening, edge detection, noise reduction, or other operations that can help the machine to learn specific characteristics of an image.\n",
    "\n",
    "#### A pooling layer that reduces the image dimensionality without losing important features or patterns.\n",
    "\n",
    "#### A fully connected layer also known as the dense layer, in which the results of the convolutional layers are fed through one or more neural layers to generate a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"## Build Covolutional Neural Network (CNN) Classification Model\"\"\"\n",
    "\n",
    "# Import Necessary Keras Libraries\n",
    "#(Here Keras is using tensor flow as backend engine)\n",
    "\n",
    "# A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.Unlike functional model A Sequential model is not appropriate when: Your model has multiple inputs or multiple outputs. Any of your layers has multiple inputs or multiple outputs.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten,Dropout\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "\n",
    "# Define model paramters\n",
    "num_classes = 2 #as we have two categories with mask and without mask\n",
    "batch_size = 32 #batch_size is how many images to pass through a neural network before internal parameters of the model are updated during back propagation\n",
    "#(Back-propagation i s the essence of neural net training. It is the practice of fine-tuning the weights of a neural net based on the error rate)\n",
    "\n",
    "# Build CNN model using Sequential API\n",
    "model=Sequential() # initializng neural network by using Sequential()\n",
    "\n",
    "#First layer group containing Convolution, Relu and MaxPooling layers\n",
    "model.add(Conv2D(64,(3,3),input_shape=(img_rows, img_cols, 1))) # here Conv2D means Convolution layer, 64 is filters they are learnable weights learned using back propagation, layers near inputs learns lesser convolution filters while near output they learns more.\n",
    "# (3,3) is kernal size, it signifies leangth of 1D convolutional window (use to learn filters and reduce volume size)\n",
    "# input_shape contains input_shape of single image; here 1 represents channel type i.e. grey scale (for colour image it is 3). \n",
    "\n",
    "##Activation is done using relu (rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.)\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# use to reduce the spacial size of representation i.e to reduce amount of parameters and computation in the network progressively. It operates on each feature map independently\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Second layer group containing Convolution, Relu and MaxPooling layers\n",
    "#Similarly 2nd layer is created to extract feature of the image. here filter size 128 so max. filters can be extracted from image\n",
    "model.add(Conv2D(128,(3,3)))\n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "\n",
    "#Flatten and Dropout Layer to stack the output convolutions above as well as cater overfitting\n",
    "model.add(Flatten()) #Fully connected layer depicted by Flatten(). it converts convolutional data into 1D array to input into next layer\n",
    "model.add(Dropout(0.5)) #Dropout use to reduce overfitting in neural network\n",
    "\n",
    "# Softmax Classifier\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(num_classes,activation='softmax')) #softmax activation function use for multi class classification problem, it reports confidence score for each class\n",
    "\n",
    "print(model.summary()) #Once a model is \"built\", you can call its summary() method to display its contents:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OUTPUT: final output has 2 nodes with mask and without mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"## Plot the Model\"\"\"\n",
    "\n",
    "# Plot the model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='face_mask_detection_architecture.png') #it takes 2 input arguments 1. model variable name and 2. name with which this image diagram is to me saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"## Train the Model\"\"\"\n",
    "\n",
    "from keras.optimizers import Adam #Here adam is the optimizer. Adams computes individual learning rate for different parameters\n",
    "\n",
    "epochs = 50 #increase epochs gives better optimized accuracy but training time will increase \n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = Adam(lr=0.001), #learning rate = 0.001\n",
    "              metrics = ['accuracy']) #loss function => compute the quantity that to be reduce during training i.e used to optimize the parameters\n",
    "# metrics here is used to compute accuracy rate across all predictions\n",
    "\n",
    "#fitting the model with different paraments and computing the output\n",
    "fitted_model = model.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    epochs = epochs,\n",
    "    validation_split=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTPUT: we got training accuracy 100% and validation accuracy= 84.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"## Plot the Training Loss & Accuracy\"\"\"\n",
    "\n",
    "\n",
    "#history collects the history of model training and keep the details of training and validation data\n",
    "from matplotlib import pyplot as plt\n",
    "# Plot Training and Validation Loss\n",
    "plt.plot(fitted_model.history['loss'],'r',label='training loss')\n",
    "plt.plot(fitted_model.history['val_loss'],label='validation loss')\n",
    "plt.xlabel('Number of Epochs') # x axis\n",
    "plt.ylabel('Loss Value') # y axis\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.plot(fitted_model.history['accuracy'],'r',label='training accuracy')\n",
    "plt.plot(fitted_model.history['val_accuracy'],label='validation accuracy')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTPUT: \n",
    "\n",
    "## the validation model is a bit overfitted as it reduces toa certaing value and then increases with increase in epochs\n",
    "\n",
    "## And accuracy of validation and training model is a bit comparable and is good enough "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"## Save or Serialize the Model (so tahat we can reuse it at any time) \"\"\"\n",
    "\n",
    "# Save or Serialize the model with the name face_mask_detection_alert_system\n",
    "model.save('face_mask_detection_alert_system.h5') #h5 is a keras file format use to store deep learning model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
